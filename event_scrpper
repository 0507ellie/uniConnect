from __future__ import annotations
from dataclasses import dataclass
from typing import Optional
from datetime import datetime, timedelta
import time
import json
import requests
from bs4 import BeautifulSoup

# Event and EventTree classes
@dataclass
class Event:
    name: str
    desc: str
    location: Optional[str]
    sorting_info: tuple[int, str, str]
    post_time: int
    image_src: Optional[str] = None

    def __init__(self, name: str, desc: str, location: str, sorting_info: tuple[int, str, str], post_time: int,
                 image: Optional[str] = None):
        self.name = name
        self.desc = desc
        self.location = location
        self.sorting_info = sorting_info
        self.post_time = post_time
        self.image = image

    def to_dict(self) -> dict:
        return {
            "name": self.name,
            "desc": self.desc,
            "location": self.location,
            "sorting_info": {"time": self.sorting_info[0], "college": self.sorting_info[1], "category": self.sorting_info[2]},
            "post_time": self.post_time,
            "image_src": self.image
        }

class EventTree:
    _root: Optional[Event]
    _subtrees: list[EventTree]

    def __init__(self, root: Optional[Event], subtrees: list[EventTree]) -> None:
        self._root = root
        self._subtrees = subtrees

    def is_empty(self) -> bool:
        return self._root is None

    def insert(self, event: Event) -> None:
        time, college, category = event.sorting_info
        event_day = datetime.fromtimestamp(time).strftime('%A')
        day_tree = self._find_or_create_subtree(event_day)
        college_tree = day_tree._find_or_create_subtree(college)
        category_tree = college_tree._find_or_create_subtree(category)
        event_node = EventTree(event, [])
        category_tree._subtrees.append(event_node)

    def _find_or_create_subtree(self, name: str) -> 'EventTree':
        for subtree in self._subtrees:
            if subtree._root and subtree._root.name == name:
                return subtree
        temp_event = Event(name, "", "", (0, "", ""), 0, "")
        new_tree = EventTree(temp_event, [])
        self._subtrees.append(new_tree)
        return new_tree

    def print_tree(self, level: int = 0) -> None:
        if self._root:
            print("  " * level + self._root.name)
        for subtree in self._subtrees:
            subtree.print_tree(level + 1)

    def to_dict(self) -> dict:
        return {
            "root": self._root.to_dict() if self._root else None,
            "subtrees": [subtree.to_dict() for subtree in self._subtrees]
        }

# Scraping Functions (all using requests)
def scrape_utsu(url: str, college: str) -> list[Event]:
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    events = []

    # Adjust based on actual HTML structure (example placeholders)
    event_containers = soup.find_all('div', role='gridcell') or soup.find_all('div', class_='kbf0gd')

    for container in event_containers:
        name_elem = container.find('div') or container.find('h3')
        name = name_elem.text.strip() if name_elem and name_elem.text.strip() else "Unnamed Event"
        desc = container.find('p').text.strip() if container.find('p') else ""
        location = container.find('span', class_='location').text.strip() if container.find('span', class_='location') else None
        time_str = container.find('span', class_='date').text if container.find('span', class_='date') else "2025-03-17"
        try:
            event_time = int(datetime.strptime(time_str, '%Y-%m-%d').timestamp())
        except ValueError:
            event_time = int(time.time())
        image = container.find('img')['src'] if container.find('img') else None

        event = Event(name, desc, location, (event_time, college, "Programming"), int(time.time()), image)
        events.append(event)
    return events

def scrape_folio(url: str, college: str) -> list[Event]:
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    events = []
    event_containers = soup.find_all('div', class_='entity-list-contnt-container')  # Adjust class
    for container in event_containers:
        name = container.find('h3').text.strip() if container.find('h3') else "Unnamed Event"
        desc = container.find('p', class_='description').text.strip() if container.find('p', class_='description') else ""
        location = container.find('span', class_='location').text.strip() if container.find('span', class_='location') else None
        time_str = container.find('span', class_='date').text if container.find('span', class_='date') else "2025-03-17"
        try:
            event_time = int(datetime.strptime(time_str, '%Y-%m-%d').timestamp())
        except ValueError:
            event_time = int(time.time())
        image = container.find('img')['src'] if container.find('img') else None
        events.append(Event(name, desc, location, (event_time, college, "General"), int(time.time()), image))
    return events

def scrape_assu(url: str, college: str) -> list[Event]:
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    events = []
    event_containers = soup.find_all('li', class_='event')  # Adjust class
    for container in event_containers:
        name = container.find('h4').text.strip() if container.find('h4') else "Unnamed Event"
        desc = container.find('p').text.strip() if container.find('p') else ""
        location = container.find('span', class_='location').text.strip() if container.find('span', class_='location') else None
        time_str = container.find('time').text if container.find('time') else "2025-03-17"
        try:
            event_time = int(datetime.strptime(time_str, '%Y-%m-%d').timestamp())
        except ValueError:
            event_time = int(time.time())
        image = container.find('img')['src'] if container.find('img') else None
        events.append(Event(name, desc, location, (event_time, college, "General"), int(time.time()), image))
    return events

def scrape_vic(url: str, college: str) -> list[Event]:
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    events = []
    event_containers = soup.find_all('div', class_='Int7p6')
    for container in event_containers:
        name_elem = container.find('div') or container.find('h3')
        name = name_elem.text.strip() if name_elem and name_elem.text.strip() else "Unnamed Event"
        desc_elem = container.find('p') or container.find('div', class_='event-details')
        desc = desc_elem.text.strip() if desc_elem else ""
        location_elem = container.find('span', class_='location')
        location = location_elem.text.strip() if location_elem else None
        time_elem = container.find('div', string=lambda text: text and any(t in text for t in ['a.m.', 'p.m.']))
        date_elem = container.find('div', string=lambda text: text and text.isdigit() and len(text) <= 2)
        time_str = time_elem.text if time_elem else "12:00 a.m."
        day_str = date_elem.text if date_elem else "17"
        try:
            event_date = datetime.strptime(f"2025-03-{day_str} {time_str}", '%Y-%m-%d %I:%M %p')
            event_time = int(event_date.timestamp())
        except ValueError:
            event_time = int(time.time())
        image = None
        event = Event(name, desc, location, (event_time, college, "Events"), int(time.time()), image)
        events.append(event)
    return events

def scrape_uc(url: str, college: str) -> list[Event]:
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    events = []
    event_containers = soup.find_all('div', class_='o-listing__list no-feature')
    for container in event_containers:
        name = container.find('h3').text.strip() if container.find('h3') else "Unnamed Event"
        desc = container.find('p').text.strip() if container.find('p') else ""
        location = container.find('span', class_='location').text.strip() if container.find('span', class_='location') else None
        time_str = container.find('time').text if container.find('time') else "2025-03-17"
        try:
            event_time = int(datetime.strptime(time_str, '%Y-%m-%d').timestamp())
        except ValueError:
            event_time = int(time.time())
        image = container.find('img')['src'] if container.find('img') else None
        events.append(Event(name, desc, location, (event_time, college, "General"), int(time.time()), image))
    return events


def scrape_trinity(url: str, college: str) -> list[Event]:
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        events = []

        # Find the events container
        events_container = soup.find('div', class_='events-desc')
        if not events_container:
            print("No events container found for Trinity")
            return events

        # Find the list of events
        event_list = events_container.find('ul', class_='list-clean')
        if not event_list:
            print("No event list found for Trinity")
            return events

        # Find individual event items
        event_items = event_list.find_all('li')
        if not event_items:
            print("No event items found for Trinity")
            return events

        for item in event_items:
            # Extract name (assume it's the first significant text block)
            name_elem = item.find('h2') or item.find('div', recursive=True)
            name = name_elem.text.strip().split('\n')[0] if name_elem and name_elem.text.strip() else "Unnamed Event"

            # Extract description and other details (split the text)
            full_text = item.get_text(separator="\n").strip().split('\n')
            desc = ""
            location = None
            time_str = "2025-03-17"  # Default date

            for line in full_text:
                line = line.strip()
                if line and not any(keyword in line.lower() for keyword in ['from', 'to', 'location:']):
                    desc += line + " "
                elif 'from' in line.lower() and 'to' in line.lower():
                    time_str = line  # e.g., "Tuesday, March 18, 2025 from 1:00 pm to 7:00 pm"
                elif line.lower().startswith('location:'):
                    location = line.replace('location:', '').strip()

            desc = desc.strip() if desc else ""

            # Parse time
            try:
                # Extract date part (e.g., "Tuesday, March 18, 2025")
                date_part = time_str.split('from')[0].strip().replace('Tuesday,', '').strip()
                event_date = datetime.strptime(date_part, '%B %d, %Y')
                event_time = int(event_date.timestamp())
            except ValueError:
                try:
                    # Try a simpler format if needed
                    event_date = datetime.strptime(time_str.split(',')[1].strip(), '%B %d, %Y')
                    event_time = int(event_date.timestamp())
                except ValueError:
                    event_time = int(time.time())  # Default to current time

            # Extract image (check for thumbnail or img tag)
            image_elem = item.find('img') or item.find('div', class_='elementor-post__thumbnail')
            image = image_elem['src'] if image_elem and 'src' in image_elem.attrs else None

            # Create Event object
            event = Event(
                name=name,
                desc=desc,
                location=location,
                sorting_info=(event_time, college, "General"),
                post_time=int(time.time()),
                image=image
            )
            events.append(event)

        return events
    except requests.RequestException as e:
        print(f"Trinity scrape failed: {e}")
        return []


def scrape_innis(url: str, college: str) -> list[Event]:
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        events = []

        # Find the main events container
        event_container = soup.find('div', class_='elementor-posts-container')
        if not event_container:
            print("No event container found for Innis")
            return events

        # Find individual event articles
        event_articles = event_container.find_all('article', class_='elementor-post')
        if not event_articles:
            print("No event articles found for Innis")
            return events

        print(f"Found {len(event_articles)} event articles for Innis")

        for article in event_articles:
            # Extract name
            name_elem = article.find('h2', class_='elementor-heading-title')
            name = name_elem.text.strip() if name_elem else "Unnamed Event"
            print(f"Name extracted: {name}")  # Debug print

            # Extract description (look for text editor div or any p tag)
            desc_elem = article.find('div', class_='elementor-widget-text-editor') or article.find('p')
            desc = desc_elem.text.strip() if desc_elem else ""
            print(f"Description extracted: {desc}")  # Debug print

            # Extract location (not explicitly tagged; try to infer)
            location_elem = article.find('span', class_='location')
            location = location_elem.text.strip() if location_elem else None
            print(f"Location extracted: {location}")  # Debug print

            # Extract time (try to find a date string in the text)
            full_text = article.get_text(separator="\n").strip()
            time_str = "2025-03-17"  # Default date
            for line in full_text.split('\n'):
                line = line.strip()
                if any(keyword in line.lower() for keyword in ['from', 'to', 'am', 'pm']):
                    time_str = line
                    break
            try:
                # Attempt to parse a date like "March 18, 2025" or "2025-03-18"
                date_part = next(
                    (part for part in time_str.split() if any(word in part.lower() for word in ['march', '2025'])),
                    "2025-03-17")
                event_date = datetime.strptime(date_part,
                                               '%B %d, %Y') if 'march' in date_part.lower() else datetime.strptime(
                    date_part, '%Y-%m-%d')
                event_time = int(event_date.timestamp())
            except ValueError:
                event_time = int(time.time())  # Default to current time
            print(f"Time string: {time_str}, Parsed time: {datetime.fromtimestamp(event_time)}")  # Debug print

            # Extract image
            image_elem = article.find('div', class_='elementor-post__thumbnail')
            image = image_elem.find('img')['src'] if image_elem and image_elem.find('img') else None
            print(f"Image src: {image}")  # Debug print

            # Create Event object
            event = Event(
                name=name,
                desc=desc,
                location=location,
                sorting_info=(event_time, college, "General"),
                post_time=int(time.time()),
                image=image
            )
            events.append(event)

        return events
    except requests.RequestException as e:
        print(f"Innis scrape failed: {e}")
        return []


def scrape_woodsworth(url: str, college: str) -> list[Event]:
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    events = []

    # Find all event containers
    event_containers = soup.find_all('div', class_='item-link-wrapper')

    for container in event_containers:
        # Extract event name (assume it's in a nested div or the first text block)
        name_elem = container.find('div') or container.find('span')
        name = name_elem.text.strip().split('\n')[0] if name_elem and name_elem.text.strip() else "Unnamed Event"

        # Extract description (assume it's the remaining text)
        desc_elem = container.find_all('div', recursive=True)  # Get all nested divs
        desc_text = ' '.join(elem.text.strip() for elem in desc_elem if elem.text.strip())
        desc = desc_text.replace(name, '').strip() if desc_text else ""

        # Extract location (hypothetical; adjust based on actual HTML)
        location_elem = container.find('span', class_='location')
        location = location_elem.text.strip() if location_elem else None

        # Extract time (e.g., "Thursday at 11:30 p.m.")
        time_elem = container.find('div', string=lambda text: text and 'at' in text.lower())
        if time_elem:
            time_str = time_elem.text.strip()
            try:
                # Parse day and time (e.g., "Thursday at 11:30 p.m.")
                day, time_part = time_str.split('at')
                day = day.strip()
                time_part = time_part.strip()
                # Assume current year (2025) and month (March) for simplicity
                event_date = datetime.strptime(f"2025-03-{day} {time_part}", '%Y-%m-%A %I:%M %p')
                event_time = int(event_date.timestamp())
            except ValueError:
                event_time = int(time.time())  # Default to current time
        else:
            event_time = int(time.time())

        # Extract image (look for img tag within the container)
        image_elem = container.find('img')
        image = image_elem['src'] if image_elem else None

        # Create Event object
        event = Event(
            name=name,
            desc=desc,
            location=location,
            sorting_info=(event_time, college, "Events"),
            post_time=int(time.time()),
            image=image
        )
        events.append(event)

    return events
# Save to JSON
def save_to_json(event_tree: EventTree, filename: str = "events.json") -> None:
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(event_tree.to_dict(), f, indent=4)
        print(f"Data saved to {filename}")
    except Exception as e:
        print(f"Error saving to {filename}: {e}")

# Main Execution
if __name__ == "__main__":
    websites = {
        "UTSU": ("https://www.utsu.ca/sc-programming/", "UTSU", scrape_utsu),
        "Folio_Activities": ("https://folio.utoronto.ca/students/activities?endorsementIds=4623183&page=1&studentSiteId=1", "Folio", scrape_folio),
        "Folio_Events": ("https://folio.utoronto.ca/students/events", "Folio", scrape_folio),
        "ASSU": ("https://assu.ca/wp/get-involved/", "ASSU", scrape_assu),
        "Vic": ("https://www.vusac.ca/events", "Vic", scrape_vic),
        "UC": ("https://www.uc.utoronto.ca/about-uc-connect-us-events", "UC", scrape_uc),
        "Trinity": ("https://www.trinity.utoronto.ca/discover/calendar/", "Trinity", scrape_trinity),
        "Innis": ("https://innis.utoronto.ca/happening-at-innis/", "Innis", scrape_innis),
        "Woodsworth": ("https://www.mywcsa.com/current-events-instagram", "Woodsworth", scrape_woodsworth),
    }

    event_tree = EventTree(None, [])

    for site_name, (url, college, scrape_func) in websites.items():
        print(f"Scraping {site_name}...")
        try:
            events = scrape_func(url, college)
            for event in events:
                event_tree.insert(event)
        except Exception as e:
            print(f"Error scraping {site_name}: {e}")
        time.sleep(1)  # Rate limiting

    print("\nEvent Tree Structure:")
    event_tree.print_tree()

    save_to_json(event_tree, "scraped_events.json")
